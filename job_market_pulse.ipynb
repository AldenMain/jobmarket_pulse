{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9170acfe-c7a2-422b-8062-6ec0fc99a2f5",
   "metadata": {},
   "source": [
    "## Job Market Pulse "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1d5ba1-46ae-4612-8b20-14e53c3ea7f5",
   "metadata": {},
   "source": [
    "# Job Market Pulse\n",
    "\n",
    "A Python-based tool to analyze and optimize my job search using data-driven insights. I call it David vs. Immigration Policy, jokes, Job-Market pulse is more palpable (this ones for you Hiring agents and HR reps)...\n",
    "\n",
    "## Features\n",
    "\n",
    "- Visualizes my application response times\n",
    "- Tracks industry-wise outcomes\n",
    "- Extracts keywords from job ads to optimize my CV\n",
    "- Highlights which strategies (custom cover letters, LinkedIn reach-outs) are actually working\n",
    "\n",
    "## Technologies\n",
    "\n",
    "- Python\n",
    "- pandas\n",
    "- seaborn & matplotlib\n",
    "- sklearn & WordCloud\n",
    "- CSV as a lightweight backend\n",
    "\n",
    "## How to Use\n",
    "\n",
    "1. Create `applications.csv`\n",
    "2. Run `job_tracker.py` generating visual insights.\n",
    "3. Use the data to adjust my job search strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6784c9a3-719e-44e6-9662-fc8f6f951356",
   "metadata": {},
   "source": [
    "Job_Title,Company,Industry,Application_Date,Response_Date,Outcome,CV_Version,Cover_Letter_Customized,LinkedIn_Connection,Location,Salary_Range,Job_Description\n",
    "Data Analyst,Globex Corp,Healthcare,2025-03-10,2025-03-14,Rejected,CV_v2,Yes,Yes,Geneva,80000-100000,\"Responsible for analyzing healthcare data...\"\n",
    "Machine Learning Engineer,Initech,Tech,2025-03-11,,Ghosted,CV_v1,No,No,Berlin,,\"Develop predictive models using Python and TensorFlow...\"\n",
    "Business Intelligence Analyst,Hooli,Finance,2025-03-12,2025-03-17,Interview,CV_v3,Yes,Yes,Zurich,90000-110000,\"Create dashboards and work with SQL...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c52b1-dced-455d-9949-5e755f47f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import datetime\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(\"applications.csv\", parse_dates=[\"Application_Date\", \"Response_Date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a451284-573c-49d4-b2c5-846d24da4f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de813107-234e-4287-8a27-cdb71434e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names if needed\n",
    "df.columns = [col.strip().replace(\" \", \"_\") for col in df.columns]\n",
    "\n",
    "# --- 1. Basic Stats ---\n",
    "print(\"Total applications:\", len(df))\n",
    "print(\"Responses received:\", df['Response_Date'].notna().sum())\n",
    "print(\"Interview rate:\", (df['Outcome'] == 'Interview').mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed696806-33ac-4aac-aa6f-b784b8a13fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Time to Response ---\n",
    "df['Days_to_Response'] = (df['Response_Date'] - df['Application_Date']).dt.days\n",
    "sns.histplot(df['Days_to_Response'].dropna(), bins=10)\n",
    "plt.title(\"Days Between Application and Response\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Number of Applications\")\n",
    "plt.show()\n",
    "\n",
    "# --- 3. Outcome by Industry ---\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(data=df, x='Industry', hue='Outcome')\n",
    "plt.title(\"Outcomes by Industry\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69829f81-ee80-4b7e-ad52-35d431eb32d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Keyword Extraction ---\n",
    "job_descriptions = df['Job_Description'].dropna().values\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=50)\n",
    "X = vectorizer.fit_transform(job_descriptions)\n",
    "word_freq = X.sum(axis=0).A1\n",
    "keywords = vectorizer.get_feature_names_out()\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400).generate_from_frequencies(dict(zip(keywords, word_freq)))\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Top Keywords from Job Descriptions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca30165-493a-4b91-8c14-c65715545c3e",
   "metadata": {},
   "source": [
    "## No response at all:\n",
    "The black hole of job applications—where hope goes to scream silently into the void.\n",
    "\n",
    "I realise I am not alone. Most modern recruitment systems are designed less for human interaction and more for funneling the unwashed masses through a Kafkaesque filter of keyword checks, HR apathy, and ATS algorithms that would ghost their own creators.\n",
    "\n",
    "But here's the good news: my lack of rejections is data. In fact, it's some of the most valuable data—I just have to read the silence correctly.\n",
    "\n",
    "#### 1 - My resume didn’t even reach a human.\n",
    "Translation: ATS filtered you out. Time to play the keyword game, not the competence game.\n",
    "\n",
    "#### 2 - My resume was seen, but didn’t spark.\n",
    "I was beige at KitKat. Either:\n",
    "I'm not signaling industry alignment\n",
    "or my resume has a \"junior coder just left bootcamp\" smell\n",
    "Or worse, it’s just... fine. And fine is fatal.\n",
    "#### 3- No one is reading applications at all.\n",
    "The job post is a formality, already filled internally or paused.\n",
    "(I'm positing discovering a depressingly high number fall into this category.)\n",
    "\n",
    "time to create a ghost rate metric: \n",
    "- Plot ghost rate by Industry\n",
    "- Plot ghost rate by CV version\n",
    "- Plot ghost rate by LinkedIn connection (did you message someone? yes/no)\n",
    "This transforms my existential despair into usable intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede572ce-c666-4d04-b728-de16b0a9db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ghost rate metric\n",
    "\n",
    "['Ghosted'] = df['Outcome'].isna() & df['Response_Date'].isna()\n",
    "ghost_rate = df['Ghosted'].mean()\n",
    "print(f\"Ghosted rate: {ghost_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2b1557-80d5-4e7f-b899-4b961e1349ac",
   "metadata": {},
   "source": [
    "## Adding Keyword Matching from CV to Job Ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7bc200-768e-4973-8a76-e498285b840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming your CV text is in a string\n",
    "with open(\"my_cv.txt\", \"r\") as file:\n",
    "    cv_text = file.read()\n",
    "\n",
    "# TF-IDF between your CV and job ads\n",
    "job_descs = df['Job_Description'].dropna().tolist()\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform([cv_text] + job_descs)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()\n",
    "\n",
    "df.loc[df['Job_Description'].notna(), 'CV_Match_Score'] = similarities\n",
    "print(df[['Job_Title', 'CV_Match_Score']].sort_values(by='CV_Match_Score', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cdf4f3-c569-46f9-b6ae-f532215d1d2f",
   "metadata": {},
   "source": [
    "Do I get ghosted more when my CV is a bad match?\n",
    "What keywords am I consistently missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f541a07-6e14-40c1-8b04-705a6d6ad21d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ac55fe3-ab8b-4093-8ead-cd36ddc457bf",
   "metadata": {},
   "source": [
    "Sidequest: LinkedIn Cold Message Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8204f7-ee7c-4900-adf1-385749cb72b0",
   "metadata": {},
   "source": [
    "- Add a field to my CSV:\n",
    "\n",
    "- LinkedIn_Contacted: Yes/No\n",
    "- Contact_Name: If applicable\n",
    "- Analyze: Ghost rate when you didn’t message anyone? Probably high. \n",
    "        Response rate after connecting with someone? Slightly less miserable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad3c2bb-f81d-4d8a-8354-6b0b4aa92cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
